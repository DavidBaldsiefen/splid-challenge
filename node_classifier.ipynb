{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 00:46:35.158382: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-21 00:46:35.158445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-21 00:46:35.159567: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-21 00:46:35.167940: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-21 00:46:36.081128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from base import datahandler, prediction_models, evaluation, classifier, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths\n",
    "challenge_data_dir = Path('dataset/phase_1_v2')\n",
    "data_dir = challenge_data_dir / \"train\"\n",
    "labels_dir = challenge_data_dir / 'train_labels.csv'\n",
    "\n",
    "split_dataframes = datahandler.load_and_prepare_dataframes(data_dir, labels_dir, dtype=np.float32)\n",
    "\n",
    "#some_dataframes = {df_k : split_dataframes[df_k] for df_k in list(split_dataframes.keys())[:1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Creating Generator=======================\n",
      "Seed: 181\n",
      "nTrain: 1520 nVal: 380 (0.80)\n",
      "Padding: zero\n",
      "Horizons: 16-192 @ stride 2\n",
      "Scaling: True  \n",
      "Sin-Transforming features: ['Longitude (deg)', 'True Anomaly (deg)', 'Argument of Periapsis (deg)']\n",
      "Sin-Cos-Transforming features: []\n",
      "Adding linear timeindex.\n",
      "Final 13 input features: ['Eccentricity', 'Semimajor Axis (m)', 'Inclination (deg)', 'RAAN (deg)', 'Latitude (deg)', 'Longitude (sin)', 'True Anomaly (sin)', 'Argument of Periapsis (sin)', 'LinearTimeIndex'] + overview of ['Eccentricity', 'Longitude (sin)', 'RAAN (deg)'] (mean) and ['Latitude (deg)'] (std)\n",
      "=========================Finished Generator=======================\n"
     ]
    }
   ],
   "source": [
    "input_features = ['Eccentricity', 'Semimajor Axis (m)', 'Inclination (deg)', 'RAAN (deg)',\n",
    "       'Argument of Periapsis (deg)', 'True Anomaly (deg)', 'Latitude (deg)',\n",
    "       'Longitude (deg)', 'Altitude (m)', 'X (m)', 'Y (m)', 'Z (m)',\n",
    "       'Vx (m/s)', 'Vy (m/s)', 'Vz (m/s)']\n",
    "\n",
    "input_features_reduced = ['Eccentricity', 'Semimajor Axis (m)', 'Inclination (deg)', 'RAAN (deg)',\n",
    "       'Argument of Periapsis (deg)', 'True Anomaly (deg)', 'Latitude (deg)',\n",
    "       'Longitude (deg)', 'Altitude (m)']\n",
    "\n",
    "input_features_reduced_further = ['Eccentricity', 'Semimajor Axis (m)', 'Inclination (deg)', 'RAAN (deg)', 'Latitude (deg)', 'Longitude (deg)']\n",
    "input_features_new = ['Eccentricity', 'Semimajor Axis (m)', 'Inclination (deg)', 'RAAN (deg)', 'Latitude (deg)', 'Longitude (deg)',\n",
    "                  'Argument of Periapsis (deg)', 'True Anomaly (deg)']\n",
    "label_features=['EW', 'EW_Type', 'EW_Node', 'EW_Node_Location', 'NS', 'NS_Type', 'NS_Node', 'NS_Node_Location']\n",
    "\n",
    "ds_gen = datahandler.DatasetGenerator(split_df=split_dataframes,\n",
    "                                      non_transform_features=['Eccentricity',\n",
    "                                                              'Semimajor Axis (m)',\n",
    "                                                              'Inclination (deg)',\n",
    "                                                              'RAAN (deg)',\n",
    "                                                              #'Argument of Periapsis (deg)',\n",
    "                                                              #'True Anomaly (deg)',\n",
    "                                                              #'Longitude (deg)',\n",
    "                                                              'Latitude (deg)'],\n",
    "                                      diff_transform_features=[],\n",
    "                                      sin_transform_features=['Longitude (deg)',\n",
    "                                                              'True Anomaly (deg)',\n",
    "                                                              'Argument of Periapsis (deg)'],#['Longitude (deg)', 'Argument of Periapsis (deg)', 'RAAN (deg)'],\n",
    "                                      sin_cos_transform_features=[],\n",
    "                                      overview_features_mean=['Eccentricity', 'Longitude (sin)', 'RAAN (deg)'],\n",
    "                                      overview_features_std=['Latitude (deg)'],\n",
    "                                      add_daytime_feature=False,\n",
    "                                      add_yeartime_feature=False,\n",
    "                                      add_linear_timeindex=True,\n",
    "                                      with_labels=True,\n",
    "                                      train_val_split=0.8,\n",
    "                                      input_stride=2,\n",
    "                                      padding='zero',\n",
    "                                      scale=True,\n",
    "                                      per_object_scaling=False,\n",
    "                                      pad_location_labels=0,\n",
    "                                      input_history_steps=16,\n",
    "                                      input_future_steps=192,\n",
    "                                      input_dtype=np.float32,\n",
    "                                      seed=181)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 00:48:16.704411: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 00:48:21.647779: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 00:48:21.647964: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 00:48:21.729847: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 00:48:21.730049: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 00:48:21.730165: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 00:48:23.902455: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 00:48:23.902724: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 00:48:23.902743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-21 00:48:23.902854: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 00:48:23.902883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4575 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:1c:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-DS Cardinality: tf.Tensor(5291, shape=(), dtype=int64)\n",
      "(TensorSpec(shape=(None, 104, 13), dtype=tf.float32, name=None), {'EW_Type': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'NS_Type': TensorSpec(shape=(None,), dtype=tf.int32, name=None)})\n"
     ]
    }
   ],
   "source": [
    "utils.set_random_seed(42)\n",
    "\n",
    "train_combined, val_combined = ds_gen.get_datasets(batch_size=1024, \n",
    "                                                   label_features=['EW_Type', 'NS_Type'],#, 'NS_Type'],\n",
    "                                                   with_identifier=False, \n",
    "                                                   only_nodes=True, \n",
    "                                                   shuffle=True, \n",
    "                                                   stride=1)\n",
    "print(train_combined.element_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Input (InputLayer)          [(None, 104, 13)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 99, 64)               5056      ['Input[0][0]']               \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 99, 64)               0         ['conv1d_6[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 99, 64)               0         ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 94, 64)               24640     ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 94, 64)               0         ['conv1d_7[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 94, 64)               0         ['activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 89, 64)               24640     ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 89, 64)               0         ['conv1d_8[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 89, 64)               0         ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 5696)                 0         ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 64)                   364608    ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 64)                   0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 64)                   0         ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 64)                   4160      ['dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 64)                   0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (None, 64)                   0         ['activation_14[0][0]']       \n",
      "                                                                                                  \n",
      " EW_Type (Dense)             (None, 4)                    260       ['dropout_14[0][0]']          \n",
      "                                                                                                  \n",
      " NS_Type (Dense)             (None, 4)                    260       ['dropout_14[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 423624 (1.62 MB)\n",
      "Trainable params: 423624 (1.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Starting training. Optimizing \"val_EW_Type_accuracy\"\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_EW_Type_accuracy improved from -inf to 0.47530, saving model to best_model.hdf5\n",
      "6/6 - 3s - loss: 4.6778 - EW_Type_loss: 2.2684 - NS_Type_loss: 2.0435 - EW_Type_accuracy: 0.3738 - NS_Type_accuracy: 0.6144 - val_loss: 2.3946 - val_EW_Type_loss: 1.2040 - val_NS_Type_loss: 0.7985 - val_EW_Type_accuracy: 0.4753 - val_NS_Type_accuracy: 0.7193 - 3s/epoch - 493ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_EW_Type_accuracy improved from 0.47530 to 0.63623, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 2.2480 - EW_Type_loss: 1.0613 - NS_Type_loss: 0.7837 - EW_Type_accuracy: 0.5146 - NS_Type_accuracy: 0.7159 - val_loss: 1.9948 - val_EW_Type_loss: 0.9085 - val_NS_Type_loss: 0.6690 - val_EW_Type_accuracy: 0.6362 - val_NS_Type_accuracy: 0.7193 - 313ms/epoch - 52ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_EW_Type_accuracy did not improve from 0.63623\n",
      "6/6 - 0s - loss: 1.9883 - EW_Type_loss: 0.9218 - NS_Type_loss: 0.6475 - EW_Type_accuracy: 0.5855 - NS_Type_accuracy: 0.7165 - val_loss: 1.9042 - val_EW_Type_loss: 0.9026 - val_NS_Type_loss: 0.5843 - val_EW_Type_accuracy: 0.6205 - val_NS_Type_accuracy: 0.7193 - 284ms/epoch - 47ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_EW_Type_accuracy improved from 0.63623 to 0.67740, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.8631 - EW_Type_loss: 0.8562 - NS_Type_loss: 0.5937 - EW_Type_accuracy: 0.6301 - NS_Type_accuracy: 0.7165 - val_loss: 1.7499 - val_EW_Type_loss: 0.7896 - val_NS_Type_loss: 0.5569 - val_EW_Type_accuracy: 0.6774 - val_NS_Type_accuracy: 0.7193 - 306ms/epoch - 51ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_EW_Type_accuracy improved from 0.67740 to 0.70284, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.7623 - EW_Type_loss: 0.8033 - NS_Type_loss: 0.5623 - EW_Type_accuracy: 0.6452 - NS_Type_accuracy: 0.7165 - val_loss: 1.6491 - val_EW_Type_loss: 0.7351 - val_NS_Type_loss: 0.5302 - val_EW_Type_accuracy: 0.7028 - val_NS_Type_accuracy: 0.7193 - 320ms/epoch - 53ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_EW_Type_accuracy improved from 0.70284 to 0.70734, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.6842 - EW_Type_loss: 0.7653 - NS_Type_loss: 0.5422 - EW_Type_accuracy: 0.6630 - NS_Type_accuracy: 0.7165 - val_loss: 1.5909 - val_EW_Type_loss: 0.7138 - val_NS_Type_loss: 0.5135 - val_EW_Type_accuracy: 0.7073 - val_NS_Type_accuracy: 0.7193 - 304ms/epoch - 51ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_EW_Type_accuracy improved from 0.70734 to 0.75000, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.5900 - EW_Type_loss: 0.7181 - NS_Type_loss: 0.5146 - EW_Type_accuracy: 0.6899 - NS_Type_accuracy: 0.7269 - val_loss: 1.5993 - val_EW_Type_loss: 0.7480 - val_NS_Type_loss: 0.5056 - val_EW_Type_accuracy: 0.7500 - val_NS_Type_accuracy: 0.7620 - 324ms/epoch - 54ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_EW_Type_accuracy improved from 0.75000 to 0.76497, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.5328 - EW_Type_loss: 0.7111 - NS_Type_loss: 0.4821 - EW_Type_accuracy: 0.7241 - NS_Type_accuracy: 0.7622 - val_loss: 1.4146 - val_EW_Type_loss: 0.6397 - val_NS_Type_loss: 0.4457 - val_EW_Type_accuracy: 0.7650 - val_NS_Type_accuracy: 0.8001 - 314ms/epoch - 52ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_EW_Type_accuracy improved from 0.76497 to 0.77096, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.4040 - EW_Type_loss: 0.6463 - NS_Type_loss: 0.4332 - EW_Type_accuracy: 0.7409 - NS_Type_accuracy: 0.8144 - val_loss: 1.3306 - val_EW_Type_loss: 0.5887 - val_NS_Type_loss: 0.4253 - val_EW_Type_accuracy: 0.7710 - val_NS_Type_accuracy: 0.8473 - 306ms/epoch - 51ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_EW_Type_accuracy improved from 0.77096 to 0.77171, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.3238 - EW_Type_loss: 0.6094 - NS_Type_loss: 0.4017 - EW_Type_accuracy: 0.7556 - NS_Type_accuracy: 0.8494 - val_loss: 1.2696 - val_EW_Type_loss: 0.5664 - val_NS_Type_loss: 0.3974 - val_EW_Type_accuracy: 0.7717 - val_NS_Type_accuracy: 0.8555 - 314ms/epoch - 52ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_EW_Type_accuracy did not improve from 0.77171\n",
      "6/6 - 0s - loss: 1.2708 - EW_Type_loss: 0.5763 - NS_Type_loss: 0.3920 - EW_Type_accuracy: 0.7626 - NS_Type_accuracy: 0.8545 - val_loss: 1.2411 - val_EW_Type_loss: 0.5742 - val_NS_Type_loss: 0.3707 - val_EW_Type_accuracy: 0.7710 - val_NS_Type_accuracy: 0.8675 - 286ms/epoch - 48ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_EW_Type_accuracy improved from 0.77171 to 0.78817, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.2021 - EW_Type_loss: 0.5409 - NS_Type_loss: 0.3681 - EW_Type_accuracy: 0.7753 - NS_Type_accuracy: 0.8656 - val_loss: 1.1738 - val_EW_Type_loss: 0.5254 - val_NS_Type_loss: 0.3610 - val_EW_Type_accuracy: 0.7882 - val_NS_Type_accuracy: 0.8690 - 302ms/epoch - 50ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_EW_Type_accuracy improved from 0.78817 to 0.79790, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.1390 - EW_Type_loss: 0.5040 - NS_Type_loss: 0.3502 - EW_Type_accuracy: 0.7861 - NS_Type_accuracy: 0.8717 - val_loss: 1.1314 - val_EW_Type_loss: 0.5096 - val_NS_Type_loss: 0.3421 - val_EW_Type_accuracy: 0.7979 - val_NS_Type_accuracy: 0.8750 - 306ms/epoch - 51ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_EW_Type_accuracy improved from 0.79790 to 0.80090, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.1014 - EW_Type_loss: 0.4830 - NS_Type_loss: 0.3410 - EW_Type_accuracy: 0.7936 - NS_Type_accuracy: 0.8635 - val_loss: 1.1649 - val_EW_Type_loss: 0.5234 - val_NS_Type_loss: 0.3680 - val_EW_Type_accuracy: 0.8009 - val_NS_Type_accuracy: 0.8735 - 309ms/epoch - 52ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_EW_Type_accuracy did not improve from 0.80090\n",
      "6/6 - 0s - loss: 1.0728 - EW_Type_loss: 0.4760 - NS_Type_loss: 0.3252 - EW_Type_accuracy: 0.7964 - NS_Type_accuracy: 0.8756 - val_loss: 1.1219 - val_EW_Type_loss: 0.5050 - val_NS_Type_loss: 0.3489 - val_EW_Type_accuracy: 0.8009 - val_NS_Type_accuracy: 0.8772 - 287ms/epoch - 48ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_EW_Type_accuracy improved from 0.80090 to 0.81362, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.0333 - EW_Type_loss: 0.4551 - NS_Type_loss: 0.3115 - EW_Type_accuracy: 0.8048 - NS_Type_accuracy: 0.8785 - val_loss: 1.0513 - val_EW_Type_loss: 0.4661 - val_NS_Type_loss: 0.3213 - val_EW_Type_accuracy: 0.8136 - val_NS_Type_accuracy: 0.8840 - 299ms/epoch - 50ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_EW_Type_accuracy improved from 0.81362 to 0.81737, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 1.0028 - EW_Type_loss: 0.4324 - NS_Type_loss: 0.3077 - EW_Type_accuracy: 0.8263 - NS_Type_accuracy: 0.8828 - val_loss: 1.0047 - val_EW_Type_loss: 0.4341 - val_NS_Type_loss: 0.3104 - val_EW_Type_accuracy: 0.8174 - val_NS_Type_accuracy: 0.8810 - 305ms/epoch - 51ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_EW_Type_accuracy did not improve from 0.81737\n",
      "6/6 - 0s - loss: 0.9683 - EW_Type_loss: 0.4271 - NS_Type_loss: 0.2822 - EW_Type_accuracy: 0.8278 - NS_Type_accuracy: 0.8902 - val_loss: 1.0154 - val_EW_Type_loss: 0.4601 - val_NS_Type_loss: 0.2979 - val_EW_Type_accuracy: 0.8174 - val_NS_Type_accuracy: 0.8870 - 281ms/epoch - 47ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_EW_Type_accuracy improved from 0.81737 to 0.83234, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.9225 - EW_Type_loss: 0.4000 - NS_Type_loss: 0.2659 - EW_Type_accuracy: 0.8358 - NS_Type_accuracy: 0.8966 - val_loss: 0.9766 - val_EW_Type_loss: 0.4346 - val_NS_Type_loss: 0.2873 - val_EW_Type_accuracy: 0.8323 - val_NS_Type_accuracy: 0.8982 - 294ms/epoch - 49ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_EW_Type_accuracy did not improve from 0.83234\n",
      "6/6 - 0s - loss: 0.9179 - EW_Type_loss: 0.4035 - NS_Type_loss: 0.2602 - EW_Type_accuracy: 0.8369 - NS_Type_accuracy: 0.9012 - val_loss: 0.9897 - val_EW_Type_loss: 0.4628 - val_NS_Type_loss: 0.2731 - val_EW_Type_accuracy: 0.8159 - val_NS_Type_accuracy: 0.8952 - 276ms/epoch - 46ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_EW_Type_accuracy improved from 0.83234 to 0.85105, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.8888 - EW_Type_loss: 0.3838 - NS_Type_loss: 0.2510 - EW_Type_accuracy: 0.8445 - NS_Type_accuracy: 0.9057 - val_loss: 0.9201 - val_EW_Type_loss: 0.3969 - val_NS_Type_loss: 0.2697 - val_EW_Type_accuracy: 0.8510 - val_NS_Type_accuracy: 0.8982 - 302ms/epoch - 50ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_EW_Type_accuracy did not improve from 0.85105\n",
      "6/6 - 0s - loss: 0.8835 - EW_Type_loss: 0.3699 - NS_Type_loss: 0.2607 - EW_Type_accuracy: 0.8494 - NS_Type_accuracy: 0.8976 - val_loss: 0.9092 - val_EW_Type_loss: 0.4083 - val_NS_Type_loss: 0.2491 - val_EW_Type_accuracy: 0.8451 - val_NS_Type_accuracy: 0.9102 - 280ms/epoch - 47ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_EW_Type_accuracy improved from 0.85105 to 0.85629, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.8458 - EW_Type_loss: 0.3562 - NS_Type_loss: 0.2382 - EW_Type_accuracy: 0.8558 - NS_Type_accuracy: 0.9117 - val_loss: 0.8945 - val_EW_Type_loss: 0.3825 - val_NS_Type_loss: 0.2616 - val_EW_Type_accuracy: 0.8563 - val_NS_Type_accuracy: 0.9012 - 300ms/epoch - 50ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_EW_Type_accuracy did not improve from 0.85629\n",
      "6/6 - 0s - loss: 0.8144 - EW_Type_loss: 0.3354 - NS_Type_loss: 0.2289 - EW_Type_accuracy: 0.8671 - NS_Type_accuracy: 0.9189 - val_loss: 0.9257 - val_EW_Type_loss: 0.4145 - val_NS_Type_loss: 0.2623 - val_EW_Type_accuracy: 0.8458 - val_NS_Type_accuracy: 0.8975 - 281ms/epoch - 47ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_EW_Type_accuracy did not improve from 0.85629\n",
      "6/6 - 0s - loss: 0.8250 - EW_Type_loss: 0.3466 - NS_Type_loss: 0.2301 - EW_Type_accuracy: 0.8577 - NS_Type_accuracy: 0.9148 - val_loss: 0.8372 - val_EW_Type_loss: 0.3713 - val_NS_Type_loss: 0.2190 - val_EW_Type_accuracy: 0.8451 - val_NS_Type_accuracy: 0.9184 - 285ms/epoch - 48ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_EW_Type_accuracy improved from 0.85629 to 0.86826, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.7712 - EW_Type_loss: 0.3154 - NS_Type_loss: 0.2092 - EW_Type_accuracy: 0.8764 - NS_Type_accuracy: 0.9223 - val_loss: 0.7873 - val_EW_Type_loss: 0.3430 - val_NS_Type_loss: 0.1981 - val_EW_Type_accuracy: 0.8683 - val_NS_Type_accuracy: 0.9334 - 305ms/epoch - 51ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_EW_Type_accuracy did not improve from 0.86826\n",
      "6/6 - 0s - loss: 0.7292 - EW_Type_loss: 0.2977 - NS_Type_loss: 0.1852 - EW_Type_accuracy: 0.8879 - NS_Type_accuracy: 0.9342 - val_loss: 0.8569 - val_EW_Type_loss: 0.4124 - val_NS_Type_loss: 0.1984 - val_EW_Type_accuracy: 0.8481 - val_NS_Type_accuracy: 0.9364 - 313ms/epoch - 52ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_EW_Type_accuracy improved from 0.86826 to 0.87500, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.7811 - EW_Type_loss: 0.3303 - NS_Type_loss: 0.2051 - EW_Type_accuracy: 0.8685 - NS_Type_accuracy: 0.9265 - val_loss: 0.8136 - val_EW_Type_loss: 0.3604 - val_NS_Type_loss: 0.2077 - val_EW_Type_accuracy: 0.8750 - val_NS_Type_accuracy: 0.9251 - 304ms/epoch - 51ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_EW_Type_accuracy did not improve from 0.87500\n",
      "6/6 - 0s - loss: 0.7227 - EW_Type_loss: 0.2939 - NS_Type_loss: 0.1834 - EW_Type_accuracy: 0.8898 - NS_Type_accuracy: 0.9344 - val_loss: 0.8130 - val_EW_Type_loss: 0.3597 - val_NS_Type_loss: 0.2088 - val_EW_Type_accuracy: 0.8630 - val_NS_Type_accuracy: 0.9274 - 295ms/epoch - 49ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_EW_Type_accuracy improved from 0.87500 to 0.87949, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.7132 - EW_Type_loss: 0.2953 - NS_Type_loss: 0.1737 - EW_Type_accuracy: 0.8864 - NS_Type_accuracy: 0.9374 - val_loss: 0.7773 - val_EW_Type_loss: 0.3385 - val_NS_Type_loss: 0.1961 - val_EW_Type_accuracy: 0.8795 - val_NS_Type_accuracy: 0.9379 - 334ms/epoch - 56ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_EW_Type_accuracy did not improve from 0.87949\n",
      "6/6 - 0s - loss: 0.6953 - EW_Type_loss: 0.2875 - NS_Type_loss: 0.1657 - EW_Type_accuracy: 0.8855 - NS_Type_accuracy: 0.9378 - val_loss: 0.8179 - val_EW_Type_loss: 0.3757 - val_NS_Type_loss: 0.2011 - val_EW_Type_accuracy: 0.8563 - val_NS_Type_accuracy: 0.9311 - 296ms/epoch - 49ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_EW_Type_accuracy improved from 0.87949 to 0.88997, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.7091 - EW_Type_loss: 0.2872 - NS_Type_loss: 0.1813 - EW_Type_accuracy: 0.8896 - NS_Type_accuracy: 0.9331 - val_loss: 0.7778 - val_EW_Type_loss: 0.3413 - val_NS_Type_loss: 0.1970 - val_EW_Type_accuracy: 0.8900 - val_NS_Type_accuracy: 0.9379 - 320ms/epoch - 53ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_EW_Type_accuracy improved from 0.88997 to 0.89296, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.6773 - EW_Type_loss: 0.2708 - NS_Type_loss: 0.1675 - EW_Type_accuracy: 0.8926 - NS_Type_accuracy: 0.9393 - val_loss: 0.7376 - val_EW_Type_loss: 0.3193 - val_NS_Type_loss: 0.1801 - val_EW_Type_accuracy: 0.8930 - val_NS_Type_accuracy: 0.9341 - 310ms/epoch - 52ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_EW_Type_accuracy improved from 0.89296 to 0.90045, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.6497 - EW_Type_loss: 0.2591 - NS_Type_loss: 0.1523 - EW_Type_accuracy: 0.9066 - NS_Type_accuracy: 0.9465 - val_loss: 0.7337 - val_EW_Type_loss: 0.3291 - val_NS_Type_loss: 0.1666 - val_EW_Type_accuracy: 0.9004 - val_NS_Type_accuracy: 0.9513 - 311ms/epoch - 52ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_EW_Type_accuracy did not improve from 0.90045\n",
      "6/6 - 0s - loss: 0.6420 - EW_Type_loss: 0.2496 - NS_Type_loss: 0.1546 - EW_Type_accuracy: 0.9012 - NS_Type_accuracy: 0.9424 - val_loss: 0.7319 - val_EW_Type_loss: 0.3297 - val_NS_Type_loss: 0.1644 - val_EW_Type_accuracy: 0.8922 - val_NS_Type_accuracy: 0.9491 - 294ms/epoch - 49ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_EW_Type_accuracy did not improve from 0.90045\n",
      "6/6 - 0s - loss: 0.6425 - EW_Type_loss: 0.2531 - NS_Type_loss: 0.1515 - EW_Type_accuracy: 0.9002 - NS_Type_accuracy: 0.9458 - val_loss: 0.7227 - val_EW_Type_loss: 0.3116 - val_NS_Type_loss: 0.1732 - val_EW_Type_accuracy: 0.8952 - val_NS_Type_accuracy: 0.9454 - 295ms/epoch - 49ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_EW_Type_accuracy did not improve from 0.90045\n",
      "6/6 - 0s - loss: 0.6367 - EW_Type_loss: 0.2506 - NS_Type_loss: 0.1483 - EW_Type_accuracy: 0.9040 - NS_Type_accuracy: 0.9463 - val_loss: 0.6975 - val_EW_Type_loss: 0.3109 - val_NS_Type_loss: 0.1496 - val_EW_Type_accuracy: 0.8967 - val_NS_Type_accuracy: 0.9566 - 291ms/epoch - 49ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_EW_Type_accuracy improved from 0.90045 to 0.90344, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.6106 - EW_Type_loss: 0.2369 - NS_Type_loss: 0.1367 - EW_Type_accuracy: 0.9068 - NS_Type_accuracy: 0.9560 - val_loss: 0.6933 - val_EW_Type_loss: 0.2979 - val_NS_Type_loss: 0.1589 - val_EW_Type_accuracy: 0.9034 - val_NS_Type_accuracy: 0.9521 - 319ms/epoch - 53ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_EW_Type_accuracy did not improve from 0.90344\n",
      "6/6 - 0s - loss: 0.6004 - EW_Type_loss: 0.2342 - NS_Type_loss: 0.1296 - EW_Type_accuracy: 0.9102 - NS_Type_accuracy: 0.9518 - val_loss: 0.7259 - val_EW_Type_loss: 0.3225 - val_NS_Type_loss: 0.1671 - val_EW_Type_accuracy: 0.8900 - val_NS_Type_accuracy: 0.9536 - 289ms/epoch - 48ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_EW_Type_accuracy improved from 0.90344 to 0.91093, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.5957 - EW_Type_loss: 0.2237 - NS_Type_loss: 0.1358 - EW_Type_accuracy: 0.9148 - NS_Type_accuracy: 0.9493 - val_loss: 0.6712 - val_EW_Type_loss: 0.2913 - val_NS_Type_loss: 0.1437 - val_EW_Type_accuracy: 0.9109 - val_NS_Type_accuracy: 0.9603 - 331ms/epoch - 55ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_EW_Type_accuracy did not improve from 0.91093\n",
      "6/6 - 0s - loss: 0.5841 - EW_Type_loss: 0.2237 - NS_Type_loss: 0.1241 - EW_Type_accuracy: 0.9159 - NS_Type_accuracy: 0.9565 - val_loss: 0.7089 - val_EW_Type_loss: 0.3202 - val_NS_Type_loss: 0.1523 - val_EW_Type_accuracy: 0.9004 - val_NS_Type_accuracy: 0.9566 - 294ms/epoch - 49ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_EW_Type_accuracy did not improve from 0.91093\n",
      "6/6 - 0s - loss: 0.5644 - EW_Type_loss: 0.2096 - NS_Type_loss: 0.1186 - EW_Type_accuracy: 0.9144 - NS_Type_accuracy: 0.9565 - val_loss: 0.7190 - val_EW_Type_loss: 0.3297 - val_NS_Type_loss: 0.1535 - val_EW_Type_accuracy: 0.8960 - val_NS_Type_accuracy: 0.9528 - 288ms/epoch - 48ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_EW_Type_accuracy did not improve from 0.91093\n",
      "6/6 - 0s - loss: 0.5955 - EW_Type_loss: 0.2297 - NS_Type_loss: 0.1304 - EW_Type_accuracy: 0.9153 - NS_Type_accuracy: 0.9524 - val_loss: 0.7192 - val_EW_Type_loss: 0.3225 - val_NS_Type_loss: 0.1617 - val_EW_Type_accuracy: 0.9049 - val_NS_Type_accuracy: 0.9543 - 290ms/epoch - 48ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_EW_Type_accuracy improved from 0.91093 to 0.91243, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.5821 - EW_Type_loss: 0.2230 - NS_Type_loss: 0.1242 - EW_Type_accuracy: 0.9138 - NS_Type_accuracy: 0.9563 - val_loss: 0.6485 - val_EW_Type_loss: 0.2788 - val_NS_Type_loss: 0.1347 - val_EW_Type_accuracy: 0.9124 - val_NS_Type_accuracy: 0.9566 - 305ms/epoch - 51ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_EW_Type_accuracy did not improve from 0.91243\n",
      "6/6 - 0s - loss: 0.5589 - EW_Type_loss: 0.2068 - NS_Type_loss: 0.1171 - EW_Type_accuracy: 0.9223 - NS_Type_accuracy: 0.9575 - val_loss: 0.6793 - val_EW_Type_loss: 0.3009 - val_NS_Type_loss: 0.1437 - val_EW_Type_accuracy: 0.9094 - val_NS_Type_accuracy: 0.9558 - 278ms/epoch - 46ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_EW_Type_accuracy did not improve from 0.91243\n",
      "6/6 - 0s - loss: 0.5566 - EW_Type_loss: 0.2074 - NS_Type_loss: 0.1148 - EW_Type_accuracy: 0.9189 - NS_Type_accuracy: 0.9597 - val_loss: 0.6992 - val_EW_Type_loss: 0.3026 - val_NS_Type_loss: 0.1625 - val_EW_Type_accuracy: 0.9102 - val_NS_Type_accuracy: 0.9543 - 291ms/epoch - 49ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_EW_Type_accuracy did not improve from 0.91243\n",
      "6/6 - 0s - loss: 0.5596 - EW_Type_loss: 0.2047 - NS_Type_loss: 0.1213 - EW_Type_accuracy: 0.9233 - NS_Type_accuracy: 0.9569 - val_loss: 0.6601 - val_EW_Type_loss: 0.2958 - val_NS_Type_loss: 0.1313 - val_EW_Type_accuracy: 0.9042 - val_NS_Type_accuracy: 0.9633 - 291ms/epoch - 49ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_EW_Type_accuracy did not improve from 0.91243\n",
      "6/6 - 0s - loss: 0.5550 - EW_Type_loss: 0.2146 - NS_Type_loss: 0.1079 - EW_Type_accuracy: 0.9172 - NS_Type_accuracy: 0.9633 - val_loss: 0.6761 - val_EW_Type_loss: 0.3063 - val_NS_Type_loss: 0.1378 - val_EW_Type_accuracy: 0.9109 - val_NS_Type_accuracy: 0.9626 - 299ms/epoch - 50ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_EW_Type_accuracy did not improve from 0.91243\n",
      "6/6 - 0s - loss: 0.5689 - EW_Type_loss: 0.2100 - NS_Type_loss: 0.1271 - EW_Type_accuracy: 0.9182 - NS_Type_accuracy: 0.9529 - val_loss: 0.6667 - val_EW_Type_loss: 0.2805 - val_NS_Type_loss: 0.1549 - val_EW_Type_accuracy: 0.9109 - val_NS_Type_accuracy: 0.9513 - 297ms/epoch - 49ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_EW_Type_accuracy did not improve from 0.91243\n",
      "6/6 - 0s - loss: 0.5533 - EW_Type_loss: 0.2026 - NS_Type_loss: 0.1195 - EW_Type_accuracy: 0.9240 - NS_Type_accuracy: 0.9594 - val_loss: 0.6718 - val_EW_Type_loss: 0.2957 - val_NS_Type_loss: 0.1451 - val_EW_Type_accuracy: 0.9124 - val_NS_Type_accuracy: 0.9626 - 287ms/epoch - 48ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_EW_Type_accuracy improved from 0.91243 to 0.91317, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.5424 - EW_Type_loss: 0.2024 - NS_Type_loss: 0.1093 - EW_Type_accuracy: 0.9229 - NS_Type_accuracy: 0.9628 - val_loss: 0.6227 - val_EW_Type_loss: 0.2635 - val_NS_Type_loss: 0.1292 - val_EW_Type_accuracy: 0.9132 - val_NS_Type_accuracy: 0.9626 - 297ms/epoch - 50ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_EW_Type_accuracy improved from 0.91317 to 0.91692, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.5170 - EW_Type_loss: 0.1898 - NS_Type_loss: 0.0973 - EW_Type_accuracy: 0.9272 - NS_Type_accuracy: 0.9673 - val_loss: 0.6444 - val_EW_Type_loss: 0.2858 - val_NS_Type_loss: 0.1292 - val_EW_Type_accuracy: 0.9169 - val_NS_Type_accuracy: 0.9618 - 308ms/epoch - 51ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_EW_Type_accuracy did not improve from 0.91692\n",
      "6/6 - 0s - loss: 0.5069 - EW_Type_loss: 0.1848 - NS_Type_loss: 0.0929 - EW_Type_accuracy: 0.9259 - NS_Type_accuracy: 0.9654 - val_loss: 0.6600 - val_EW_Type_loss: 0.2946 - val_NS_Type_loss: 0.1366 - val_EW_Type_accuracy: 0.9132 - val_NS_Type_accuracy: 0.9618 - 286ms/epoch - 48ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_EW_Type_accuracy did not improve from 0.91692\n",
      "6/6 - 0s - loss: 0.5248 - EW_Type_loss: 0.1915 - NS_Type_loss: 0.1049 - EW_Type_accuracy: 0.9269 - NS_Type_accuracy: 0.9656 - val_loss: 0.5959 - val_EW_Type_loss: 0.2598 - val_NS_Type_loss: 0.1082 - val_EW_Type_accuracy: 0.9169 - val_NS_Type_accuracy: 0.9716 - 312ms/epoch - 52ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_EW_Type_accuracy did not improve from 0.91692\n",
      "6/6 - 0s - loss: 0.4798 - EW_Type_loss: 0.1699 - NS_Type_loss: 0.0822 - EW_Type_accuracy: 0.9350 - NS_Type_accuracy: 0.9690 - val_loss: 0.6457 - val_EW_Type_loss: 0.2831 - val_NS_Type_loss: 0.1349 - val_EW_Type_accuracy: 0.9154 - val_NS_Type_accuracy: 0.9626 - 299ms/epoch - 50ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_EW_Type_accuracy did not improve from 0.91692\n",
      "6/6 - 0s - loss: 0.4967 - EW_Type_loss: 0.1760 - NS_Type_loss: 0.0927 - EW_Type_accuracy: 0.9318 - NS_Type_accuracy: 0.9681 - val_loss: 0.6130 - val_EW_Type_loss: 0.2704 - val_NS_Type_loss: 0.1140 - val_EW_Type_accuracy: 0.9139 - val_NS_Type_accuracy: 0.9708 - 297ms/epoch - 49ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_EW_Type_accuracy did not improve from 0.91692\n",
      "6/6 - 0s - loss: 0.5048 - EW_Type_loss: 0.1759 - NS_Type_loss: 0.1002 - EW_Type_accuracy: 0.9359 - NS_Type_accuracy: 0.9667 - val_loss: 0.6272 - val_EW_Type_loss: 0.2739 - val_NS_Type_loss: 0.1246 - val_EW_Type_accuracy: 0.9132 - val_NS_Type_accuracy: 0.9641 - 294ms/epoch - 49ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_EW_Type_accuracy did not improve from 0.91692\n",
      "6/6 - 0s - loss: 0.4926 - EW_Type_loss: 0.1721 - NS_Type_loss: 0.0920 - EW_Type_accuracy: 0.9356 - NS_Type_accuracy: 0.9669 - val_loss: 0.6520 - val_EW_Type_loss: 0.2904 - val_NS_Type_loss: 0.1332 - val_EW_Type_accuracy: 0.9139 - val_NS_Type_accuracy: 0.9611 - 290ms/epoch - 48ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_EW_Type_accuracy did not improve from 0.91692\n",
      "6/6 - 0s - loss: 0.5089 - EW_Type_loss: 0.1853 - NS_Type_loss: 0.0950 - EW_Type_accuracy: 0.9331 - NS_Type_accuracy: 0.9654 - val_loss: 0.6795 - val_EW_Type_loss: 0.2946 - val_NS_Type_loss: 0.1563 - val_EW_Type_accuracy: 0.9072 - val_NS_Type_accuracy: 0.9588 - 291ms/epoch - 48ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_EW_Type_accuracy did not improve from 0.91692\n",
      "6/6 - 0s - loss: 0.5045 - EW_Type_loss: 0.1860 - NS_Type_loss: 0.0899 - EW_Type_accuracy: 0.9316 - NS_Type_accuracy: 0.9694 - val_loss: 0.6250 - val_EW_Type_loss: 0.2835 - val_NS_Type_loss: 0.1126 - val_EW_Type_accuracy: 0.9147 - val_NS_Type_accuracy: 0.9693 - 285ms/epoch - 48ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_EW_Type_accuracy did not improve from 0.91692\n",
      "6/6 - 0s - loss: 0.5011 - EW_Type_loss: 0.1801 - NS_Type_loss: 0.0921 - EW_Type_accuracy: 0.9278 - NS_Type_accuracy: 0.9677 - val_loss: 0.6600 - val_EW_Type_loss: 0.2832 - val_NS_Type_loss: 0.1479 - val_EW_Type_accuracy: 0.9064 - val_NS_Type_accuracy: 0.9551 - 288ms/epoch - 48ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_EW_Type_accuracy did not improve from 0.91692\n",
      "6/6 - 0s - loss: 0.5269 - EW_Type_loss: 0.1878 - NS_Type_loss: 0.1101 - EW_Type_accuracy: 0.9289 - NS_Type_accuracy: 0.9620 - val_loss: 0.6303 - val_EW_Type_loss: 0.2702 - val_NS_Type_loss: 0.1312 - val_EW_Type_accuracy: 0.9169 - val_NS_Type_accuracy: 0.9626 - 285ms/epoch - 47ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_EW_Type_accuracy improved from 0.91692 to 0.91841, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.5063 - EW_Type_loss: 0.1788 - NS_Type_loss: 0.0983 - EW_Type_accuracy: 0.9312 - NS_Type_accuracy: 0.9631 - val_loss: 0.6562 - val_EW_Type_loss: 0.2727 - val_NS_Type_loss: 0.1545 - val_EW_Type_accuracy: 0.9184 - val_NS_Type_accuracy: 0.9551 - 317ms/epoch - 53ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_EW_Type_accuracy improved from 0.91841 to 0.92290, saving model to best_model.hdf5\n",
      "6/6 - 0s - loss: 0.5015 - EW_Type_loss: 0.1720 - NS_Type_loss: 0.1002 - EW_Type_accuracy: 0.9337 - NS_Type_accuracy: 0.9662 - val_loss: 0.6192 - val_EW_Type_loss: 0.2690 - val_NS_Type_loss: 0.1200 - val_EW_Type_accuracy: 0.9229 - val_NS_Type_accuracy: 0.9663 - 302ms/epoch - 50ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_EW_Type_accuracy did not improve from 0.92290\n",
      "6/6 - 0s - loss: 0.4978 - EW_Type_loss: 0.1665 - NS_Type_loss: 0.1011 - EW_Type_accuracy: 0.9384 - NS_Type_accuracy: 0.9635 - val_loss: 0.6115 - val_EW_Type_loss: 0.2634 - val_NS_Type_loss: 0.1183 - val_EW_Type_accuracy: 0.9154 - val_NS_Type_accuracy: 0.9701 - 294ms/epoch - 49ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_EW_Type_accuracy did not improve from 0.92290\n",
      "6/6 - 0s - loss: 0.5084 - EW_Type_loss: 0.1777 - NS_Type_loss: 0.1013 - EW_Type_accuracy: 0.9312 - NS_Type_accuracy: 0.9588 - val_loss: 0.6165 - val_EW_Type_loss: 0.2660 - val_NS_Type_loss: 0.1222 - val_EW_Type_accuracy: 0.9169 - val_NS_Type_accuracy: 0.9693 - 284ms/epoch - 47ms/step\n",
      "Epoch 67/300\n"
     ]
    }
   ],
   "source": [
    "utils.set_random_seed(42)\n",
    "\n",
    "#dense_model = prediction_models.Dense_NN(val_combined, conv1d_layers=[], dense_layers=[256,128,64], l2_reg=0.001, mixed_dropout=0.15, lr_scheduler=[30000,0.9], seed=0)\n",
    "#dense_model = prediction_models.CNN(train_combined, conv_layers=[[64,6],[64,3],[64,3]], l2_reg=0.001, mixed_dropout=0.15, lr_scheduler=[20000,0.8], seed=0)\n",
    "#dense_model = prediction_models.Dense_NN(train_combined, conv1d_layers=[], dense_layers=[16], l2_reg=0.0001, input_dropout=0.1, mixed_dropout=0.5, lr_scheduler=[10000,0.9], seed=0)\n",
    "#dense_model = prediction_models.LSTM_NN(train_combined, input_dropout=0.0, mixed_dropout=0.25, lstm_layers=[32,16], dense_layers=[32,16], l2_reg=0.0, lr_scheduler=[25000,0.9], seed=1)\n",
    "#dense_model = prediction_models.Dense_NN(train_combined, conv1d_layers=[], dense_layers=[1], l2_reg=0.00001, mixed_dropout=0.2, lr_scheduler=[70000,0.9], seed=0)\n",
    "\n",
    "dense_model = prediction_models.Dense_NN(val_combined,\n",
    "                                         conv1d_layers=[[64,6],[64,6],[64,6]],\n",
    "                                         conv2d_layers=[],#[32,(6,3)],[32,(6,3)],[32,(6,3)]],\n",
    "                                         dense_layers=[64,64],\n",
    "                                         lstm_layers=[],\n",
    "                                         l2_reg=0.001,\n",
    "                                         input_dropout=0.0,\n",
    "                                         mixed_dropout_dense=0.1,\n",
    "                                         mixed_dropout_cnn=0.15,\n",
    "                                         mixed_dropout_lstm=0.0,\n",
    "                                         mixed_batchnorm=False, # if True, this fucks up inference big time! maybe re-visit?\n",
    "                                         lr_scheduler=[0.005, 250, 0.9],\n",
    "                                         output_type='classification',\n",
    "                                         seed=0)\n",
    "\n",
    "#dense_model._model = create_timeseries_classification_model((65,6))\n",
    "\n",
    "dense_model.summary()\n",
    "\n",
    "# temporary fix to allow class weights\n",
    "# train_combined= train_combined.map(lambda x,y:(x,y[f'EW_Type']))\n",
    "# val_combined = val_combined.map(lambda x,y:(x,y[f'EW_Type'])) \n",
    "\n",
    "# w_0 = 1.05\n",
    "# w_1 = 1.2\n",
    "# w_2 = 1.05\n",
    "# w_3 = 0.65\n",
    "\n",
    "hist = dense_model.fit(train_combined,\n",
    "                       val_ds=val_combined,\n",
    "                       epochs=300,\n",
    "                       verbose=2,\n",
    "                       plot_hist=True,\n",
    "                       save_best_only=True,\n",
    "                       early_stopping=40,\n",
    "                       target_metric='val_EW_Type_accuracy',\n",
    "                       #class_weight={0: w_0, 1: w_1, 2: w_2, 3: w_3},\n",
    "                       callbacks=[])\n",
    "dense_model.evaluate(val_combined)\n",
    "#dense_model.model.save('models/ew_ns_classifier_new.hdf5')\n",
    "\n",
    "# \n",
    "# No transform: 14 71 0.946\n",
    "# True Anomaly + keep [float64]: 10 76 0.946\n",
    "# True Anomaly + keep [float32]: 11 78 0.953 -> not better, not worse\n",
    "# all + keep [float32]: 09 83 0.941\n",
    "# all dont keep [float32]: 20 75 0.935"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = dense_model.fit(train_combined, val_ds=val_combined, early_stopping=40, target_metric='val_EW_Type_accuracy', epochs=100, verbose=2, plot_hist=True, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense_model.model.save('submission/models/ew_ns_classifier.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gen.plot_dataset_items(val_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_df = classifier.create_prediction_df(ds_gen=ds_gen,\n",
    "                                model=dense_model,\n",
    "                                train=False,\n",
    "                                test=False,\n",
    "                                model_outputs=['EW_Type', 'NS_Type'],#, 'NS_Type'],\n",
    "                                object_limit=None,\n",
    "                                only_nodes=True,\n",
    "                                confusion_matrix=False,\n",
    "                                prediction_batches=3,\n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.960\n",
      "TP: 1767 FP: 73\n"
     ]
    }
   ],
   "source": [
    "ground_truth_df = pd.read_csv(challenge_data_dir / 'train_labels.csv')#.sort_values(['ObjectID', 'TimeIndex']).reset_index(drop=True)\n",
    "majority_df = classifier.apply_one_shot_method(preds_df=pred_df, location_df=ground_truth_df, dirs=['EW', 'NS'])\n",
    "\n",
    "# ground_truth_df=ground_truth_df.loc[ground_truth_df['TimeIndex']==0]\n",
    "# majority_df=majority_df.loc[majority_df['TimeIndex']==0]\n",
    "# ground_truth_df=ground_truth_df.loc[ground_truth_df['Direction']=='EW']\n",
    "# majority_df=majority_df.loc[majority_df['Direction']=='EW']\n",
    "\n",
    "# 0.95 with 3-layer cnn and 128@2 horizon\n",
    "\n",
    "evaluator = evaluation.NodeDetectionEvaluator(ground_truth=ground_truth_df, participant=majority_df)\n",
    "precision, recall, f2, rmse, total_tp, total_fp, total_fn, total_df = evaluator.score()\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'TP: {total_tp} FP: {total_fp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'current_learning_rate:0' shape=() dtype=float32, numpy=0.0040499996>\n"
     ]
    }
   ],
   "source": [
    "print(dense_model.model.optimizer.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/splid-gpu/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(ds_gen.scaler, open('submission/models/ew_ns_classifier_scaler_oneshot_cnn.pkl', 'wb'))\n",
    "dense_model.model.save('submission/models/ew_ns_classifier_oneshot_cnn.hdf5')\n",
    "\n",
    "#0.12 0.92 0.950 (no dropout, strong overfitting, no ft-transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splid-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

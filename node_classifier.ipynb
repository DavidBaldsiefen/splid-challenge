{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:33:18.145702: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-27 19:33:18.145763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-27 19:33:18.146585: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-27 19:33:18.153448: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-27 19:33:19.043929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from base import datahandler, prediction_models, evaluation, classifier, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths\n",
    "challenge_data_dir = Path('dataset/phase_1_v2')\n",
    "data_dir = challenge_data_dir / \"train\"\n",
    "labels_dir = challenge_data_dir / 'train_labels.csv'\n",
    "\n",
    "split_dataframes = datahandler.load_and_prepare_dataframes(data_dir, labels_dir, dtype=np.float32)\n",
    "\n",
    "#some_dataframes = {df_k : split_dataframes[df_k] for df_k in list(split_dataframes.keys())[:1000]}\n",
    "#['1012', '1383', '1385', '1386', '1471', '1473', '1474'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Creating Generator=======================\n",
      "Seed: 181\n",
      "nTrain: 1520 nVal: 380 (0.80)\n",
      "Padding: zero\n",
      "Horizons: 16-128 @ stride 1\n",
      "Scaling: True  \n",
      "Limiting True Anomaly to [0.0, 360.0] and Longitude to [-180.0, 180.0]\n",
      "Sin-Transforming features: ['Argument of Periapsis (deg)', 'Longitude (deg)']\n",
      "Sin-Cos-Transforming features: []\n",
      "Diff Transforming features: ['Eccentricity', 'Semimajor Axis (m)', 'Inclination (deg)', 'RAAN (deg)', 'Argument of Periapsis (deg)', 'True Anomaly (deg)', 'Latitude (deg)']\n",
      "Adding linear timeindex.\n",
      "Final 24 input features: ['Argument of Periapsis (deg) (diff)', 'Argument of Periapsis (sin)', 'Eccentricity', 'Eccentricity (diff)', 'Inclination (deg)', 'Inclination (deg) (diff)', 'Latitude (deg)', 'Latitude (deg) (diff)', 'LinearTimeIndex', 'Longitude (sin)', 'RAAN (deg)', 'RAAN (deg) (diff)', 'Semimajor Axis (m)', 'Semimajor Axis (m) (diff)', 'True Anomaly (deg)', 'True Anomaly (deg) (diff)'] + overview of ['Argument of Periapsis (sin)', 'Eccentricity', 'Inclination (deg)', 'Longitude (sin)', 'RAAN (deg)', 'Semimajor Axis (m)'] (mean) and ['Argument of Periapsis (sin)', 'Latitude (deg)'] (std)\n",
      "=========================Finished Generator=======================\n"
     ]
    }
   ],
   "source": [
    "input_features = ['Eccentricity', 'Semimajor Axis (m)', 'Inclination (deg)', 'RAAN (deg)',\n",
    "       'Argument of Periapsis (deg)', 'True Anomaly (deg)', 'Latitude (deg)',\n",
    "       'Longitude (deg)', 'Altitude (m)', 'X (m)', 'Y (m)', 'Z (m)',\n",
    "       'Vx (m/s)', 'Vy (m/s)', 'Vz (m/s)']\n",
    "\n",
    "input_features_reduced = ['Eccentricity', 'Semimajor Axis (m)', 'Inclination (deg)', 'RAAN (deg)',\n",
    "       'Argument of Periapsis (deg)', 'True Anomaly (deg)', 'Latitude (deg)',\n",
    "       'Longitude (deg)', 'Altitude (m)']\n",
    "\n",
    "input_features_reduced_further = ['Eccentricity', 'Semimajor Axis (m)', 'Inclination (deg)', 'RAAN (deg)', 'Latitude (deg)', 'Longitude (deg)']\n",
    "input_features_new = ['Eccentricity', 'Semimajor Axis (m)', 'Inclination (deg)', 'RAAN (deg)', 'Latitude (deg)', 'Longitude (deg)',\n",
    "                  'Argument of Periapsis (deg)', 'True Anomaly (deg)']\n",
    "label_features=['EW', 'EW_Type', 'EW_Node', 'EW_Node_Location', 'NS', 'NS_Type', 'NS_Node', 'NS_Node_Location']\n",
    "\n",
    "ds_gen = datahandler.DatasetGenerator(split_df=split_dataframes,\n",
    "                                      exclude_objects=[],\n",
    "                                      non_transform_features=['Eccentricity',\n",
    "                                                              'Semimajor Axis (m)',\n",
    "                                                              'Inclination (deg)',\n",
    "                                                              'RAAN (deg)',\n",
    "                                                              #'Argument of Periapsis (deg)',\n",
    "                                                              'True Anomaly (deg)',\n",
    "                                                              'Latitude (deg)',\n",
    "                                                              #'Longitude (deg)',\n",
    "                                                              ],\n",
    "                                      diff_transform_features=['Eccentricity',\n",
    "                                                               'Semimajor Axis (m)',\n",
    "                                                               'Inclination (deg)',\n",
    "                                                               'RAAN (deg)',\n",
    "                                                               'Argument of Periapsis (deg)',\n",
    "                                                               'True Anomaly (deg)',\n",
    "                                                               #'Longitude (deg)',\n",
    "                                                               'Latitude (deg)'\n",
    "                                                               ],\n",
    "                                      sin_transform_features=[ #'Inclination (deg)',\n",
    "                                                               #'RAAN (deg)',\n",
    "                                                               'Argument of Periapsis (deg)',\n",
    "                                                               #'True Anomaly (deg)',\n",
    "                                                               'Longitude (deg)',\n",
    "                                                               #'Latitude (deg)'\n",
    "                                                              ],\n",
    "                                      sin_cos_transform_features=[\n",
    "                                                               #'Inclination (deg)',\n",
    "                                                               #'RAAN (deg)',\n",
    "                                                               #'Argument of Periapsis (deg)',\n",
    "                                                               #'True Anomaly (deg)',\n",
    "                                                               #'Longitude (deg)',\n",
    "                                                               #'Latitude (deg)'\n",
    "                                                               ],\n",
    "                                      overview_features_mean=['Eccentricity',\n",
    "                                                              'Semimajor Axis (m)',\n",
    "                                                              'Inclination (deg)',\n",
    "                                                              'RAAN (deg)',\n",
    "                                                              'Argument of Periapsis (sin)',\n",
    "                                                              #'True Anomaly (deg)',\n",
    "                                                              #'Latitude (deg)',\n",
    "                                                              'Longitude (sin)',\n",
    "                                                              ],\n",
    "                                      overview_features_std=['Latitude (deg)',\n",
    "                                                             'Argument of Periapsis (sin)'\n",
    "                                                             ],\n",
    "                                      add_daytime_feature=False,\n",
    "                                      add_yeartime_feature=False,\n",
    "                                      add_linear_timeindex=True,\n",
    "                                      with_labels=True,\n",
    "                                      train_val_split=0.8,\n",
    "                                      input_stride=1,\n",
    "                                      padding='zero',\n",
    "                                      unify_value_ranges=True,\n",
    "                                      scale=True,\n",
    "                                      per_object_scaling=False,\n",
    "                                      pad_location_labels=0,\n",
    "                                      input_history_steps=16,\n",
    "                                      input_future_steps=128,\n",
    "                                      input_dtype=np.float32,\n",
    "                                      sort_inputs=True,\n",
    "                                      seed=181,\n",
    "                                      deepcopy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1520 [00:00<00:17, 83.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1520/1520 [00:17<00:00, 86.35it/s] \n",
      "100%|██████████| 380/380 [00:04<00:00, 86.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-DS Cardinality: tf.Tensor(15928, shape=(), dtype=int64)\n",
      "Val-DS Cardinality: tf.Tensor(3996, shape=(), dtype=int64)\n",
      "(TensorSpec(shape=(None, 144, 24), dtype=tf.float32, name=None), {'EW_Type': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'NS_Type': TensorSpec(shape=(None,), dtype=tf.int32, name=None)})\n"
     ]
    }
   ],
   "source": [
    "utils.set_random_seed(42)\n",
    "\n",
    "train_combined, val_combined = ds_gen.get_datasets(batch_size=512, \n",
    "                                                   label_features=['EW_Type', 'NS_Type'],#, 'NS_Type'],\n",
    "                                                   with_identifier=False, \n",
    "                                                   only_nodes=False, \n",
    "                                                   shuffle=True, \n",
    "                                                   stride=1,\n",
    "                                                   keep_label_stride=300,\n",
    "                                                   verbose=1)\n",
    "print(train_combined.element_spec)\n",
    "# Cardinality is below number of nodes, because sometimes EW and NS are in the same location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Input (InputLayer)          [(None, 144, 24)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 68, 48)               10416     ['Input[0][0]']               \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 68, 48)               0         ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 68, 48)               0         ['activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 64, 48)               11568     ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 64, 48)               0         ['conv1d_4[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 64, 48)               0         ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 62, 48)               6960      ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 62, 48)               0         ['conv1d_5[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 62, 48)               0         ['activation_7[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 2976)                 0         ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 64)                   190528    ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 64)                   0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 64)                   0         ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 32)                   2080      ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 32)                   0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 32)                   0         ['activation_9[0][0]']        \n",
      "                                                                                                  \n",
      " EW_Type (Dense)             (None, 4)                    132       ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " NS_Type (Dense)             (None, 4)                    132       ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 221816 (866.47 KB)\n",
      "Trainable params: 221816 (866.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Starting training. Optimizing \"val_EW_Type_accuracy\"\n",
      "Epoch 1/500\n"
     ]
    }
   ],
   "source": [
    "utils.set_random_seed(42)\n",
    "\n",
    "#dense_model = prediction_models.Dense_NN(val_combined, conv1d_layers=[], dense_layers=[256,128,64], l2_reg=0.001, mixed_dropout=0.15, lr_scheduler=[30000,0.9], seed=0)\n",
    "#dense_model = prediction_models.CNN(train_combined, conv_layers=[[64,6],[64,3],[64,3]], l2_reg=0.001, mixed_dropout=0.15, lr_scheduler=[20000,0.8], seed=0)\n",
    "#dense_model = prediction_models.Dense_NN(train_combined, conv1d_layers=[], dense_layers=[16], l2_reg=0.0001, input_dropout=0.1, mixed_dropout=0.5, lr_scheduler=[10000,0.9], seed=0)\n",
    "#dense_model = prediction_models.LSTM_NN(train_combined, input_dropout=0.0, mixed_dropout=0.25, lstm_layers=[32,16], dense_layers=[32,16], l2_reg=0.0, lr_scheduler=[25000,0.9], seed=1)\n",
    "#dense_model = prediction_models.Dense_NN(train_combined, conv1d_layers=[], dense_layers=[1], l2_reg=0.00001, mixed_dropout=0.2, lr_scheduler=[70000,0.9], seed=0)\n",
    "\n",
    "dense_model = prediction_models.Dense_NN(val_combined,\n",
    "                                         conv1d_layers=[[48,9,2,1,1],[48,5,1,1,1],[48,3,1,1,1]],\n",
    "                                         convlstm1d_layers=[],#[[16,4],[16,4],[16,4]],\n",
    "                                         conv2d_layers=[],#[32,(6,3)],[32,(6,3)],[32,(6,3)]],\n",
    "                                         dense_layers=[64,32],\n",
    "                                         lstm_layers=[],\n",
    "                                         l2_reg=0.001,\n",
    "                                         input_dropout=0.00,\n",
    "                                         mixed_dropout_dense=0.05,\n",
    "                                         mixed_dropout_cnn=0.1,\n",
    "                                         mixed_dropout_lstm=0.0,\n",
    "                                         mixed_batchnorm=False, # if True, this fucks up inference big time! maybe re-visit?\n",
    "                                         lr_scheduler=[0.005],#, 250, 0.9],\n",
    "                                         output_type='classification',\n",
    "                                         seed=0)\n",
    "\n",
    "#dense_model._model = create_timeseries_classification_model((65,6))\n",
    "\n",
    "dense_model.summary()\n",
    "\n",
    "# temporary fix to allow class weights\n",
    "# train_combined= train_combined.map(lambda x,y:(x,y[f'EW_Type']))\n",
    "# val_combined = val_combined.map(lambda x,y:(x,y[f'EW_Type'])) \n",
    "\n",
    "# w_0 = 1.05\n",
    "# w_1 = 1.2\n",
    "# w_2 = 1.05\n",
    "# w_3 = 0.65\n",
    "\n",
    "hist = dense_model.fit(train_combined,\n",
    "                       val_ds=val_combined,\n",
    "                       epochs=500,\n",
    "                       verbose=2,\n",
    "                       plot_hist=True,\n",
    "                       save_best_only=True,\n",
    "                       early_stopping=50,\n",
    "                       target_metric='val_EW_Type_accuracy',\n",
    "                       #class_weight={0: w_0, 1: w_1, 2: w_2, 3: w_3},\n",
    "                       callbacks=[])\n",
    "dense_model.evaluate(val_combined)\n",
    "#dense_model.model.save('models/ew_ns_classifier_new.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = dense_model.fit(train_combined, val_ds=val_combined, early_stopping=40, target_metric='val_EW_Type_accuracy', epochs=100, verbose=2, plot_hist=True, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense_model.model.save('submission/models/ew_ns_classifier.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gen.plot_dataset_items(val_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 711ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 1s 528ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_df = classifier.create_prediction_df(ds_gen=ds_gen,\n",
    "                                model=dense_model,\n",
    "                                train=False,\n",
    "                                test=False,\n",
    "                                model_outputs=['EW_Type', 'NS_Type'],#, 'NS_Type'],\n",
    "                                object_limit=None,\n",
    "                                only_nodes=True,\n",
    "                                confusion_matrix=False,\n",
    "                                prediction_batches=3,\n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.967\n",
      "TP: 1780 FP: 60\n"
     ]
    }
   ],
   "source": [
    "ground_truth_df = pd.read_csv(challenge_data_dir / 'train_labels.csv')#.sort_values(['ObjectID', 'TimeIndex']).reset_index(drop=True)\n",
    "# TEMPORARY: remove erronous keys from gt\n",
    "ground_truth_df=ground_truth_df.loc[((~ground_truth_df['ObjectID'].isin([1012, 1383, 1385, 1386, 1471, 1473, 1474]) & ground_truth_df['Node'] != 'ES'))].copy()\n",
    "ground_truth_df['Node'] = 'UNKNOWN'\n",
    "ground_truth_df['Type'] = 'UNKNOWN'\n",
    "\n",
    "typed_df = classifier.fill_unknown_types_based_on_preds(pred_df, ground_truth_df, dirs=['EW', 'NS'])\n",
    "classified_df = classifier.fill_unknwon_nodes_based_on_type(typed_df, dirs=['EW', 'NS'])\n",
    "\n",
    "# ground_truth_df=ground_truth_df.loc[ground_truth_df['TimeIndex']==0]\n",
    "# majority_df=majority_df.loc[majority_df['TimeIndex']==0]\n",
    "# ground_truth_df=ground_truth_df.loc[ground_truth_df['Direction']=='EW']\n",
    "# majority_df=majority_df.loc[majority_df['Direction']=='EW']\n",
    "\n",
    "# 0.95 with 3-layer cnn and 128@2 horizon\n",
    "\n",
    "# EW: 0.965, 996 36\n",
    "# NS: 0.967, 782 27\n",
    "ground_truth_eval_df = pd.read_csv(challenge_data_dir / 'train_labels.csv')\n",
    "evaluator = evaluation.NodeDetectionEvaluator(ground_truth=ground_truth_eval_df, participant=classified_df)\n",
    "precision, recall, f2, rmse, total_tp, total_fp, total_fn, total_df = evaluator.score()\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'TP: {total_tp} FP: {total_fp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ObjectID  TimeIndex  EW_Type_Pred EW_Type  NS_Type_Pred NS_Type Type Node\n",
      "21       111          0             3      NK             3      NK   na   na\n",
      "22       111        124             3      NK             3      NK   na   na\n",
      "23       111        411             3      NK             3      NK   NK   ID\n",
      "24       111        418             3      NK             3      NK   na   na\n",
      "25       111        479             2      HK             2      HK   na   na\n",
      "      ObjectID  TimeIndex Direction     Node Type\n",
      "1176      1143          0        EW  UNKNOWN   NK\n",
      "1177      1143          0        NS  UNKNOWN   NK\n",
      "1178      1143       1026        EW  UNKNOWN   NK\n",
      "1179      1143       1033        EW       ID   NK\n",
      "1180      1143       1082        NS  UNKNOWN   CK\n",
      "1181      1143       1729        EW  UNKNOWN   NK\n",
      "1182      1143       1729        NS  UNKNOWN   NK\n",
      "      ObjectID  TimeIndex Direction Node Type\n",
      "1176      1143          0        EW   SS   NK\n",
      "1177      1143          0        NS   SS   NK\n",
      "1178      1143       1026        EW   AD   NK\n",
      "1179      1143       1033        EW   ID   NK\n",
      "1180      1143       1082        NS   IK   CK\n",
      "1181      1143       1729        EW   AD   NK\n",
      "1182      1143       1729        NS   ID   NK\n"
     ]
    }
   ],
   "source": [
    "ground_truth_df.loc[((ground_truth_df['ObjectID'] == 1143) & (ground_truth_df['TimeIndex'] == 1033)), 'Type'] = 'NK'\n",
    "ground_truth_df.loc[((ground_truth_df['ObjectID'] == 1143) & (ground_truth_df['TimeIndex'] == 1033)), 'Node'] = 'ID'\n",
    "print(pred_df.loc[pred_df['ObjectID'] == 111].head(20))\n",
    "tmp = classifier.fill_unknown_types_based_on_preds(pred_df, ground_truth_df, dirs=['EW', 'NS'])\n",
    "print(tmp.loc[tmp['ObjectID'] == 1143].head(20))\n",
    "tmp = classifier.fill_unknwon_nodes_based_on_type(tmp, dirs=['EW', 'NS'])\n",
    "print(tmp.loc[tmp['ObjectID'] == 1143].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ObjectID  TimeIndex Direction Node Type classification distance matched\n",
      "6            3          0        EW   SS   EK             FP        0    True\n",
      "27          12          0        EW   SS   EK             FP        0    True\n",
      "28          12          0        NS   SS   CK             FP        0    True\n",
      "40          17          0        EW   SS   EK             FP        0    True\n",
      "41          17          0        NS   SS   CK             FP        0    True\n",
      "69          30          0        NS   SS   CK             FP        0    True\n",
      "166         78          0        NS   SS   CK             FP        0    True\n",
      "179         84          0        NS   SS   CK             FP        0    True\n",
      "192         90          0        NS   SS   CK             FP        0    True\n",
      "207         97          0        NS   SS   CK             FP        0    True\n",
      "216        101          0        NS   SS   CK             FP        0    True\n",
      "745        212        622        NS   IK   CK             FP        0    True\n",
      "855        240          0        EW   SS   EK             FP        0    True\n",
      "856        240          0        NS   SS   NK             FP        0    True\n",
      "859        241          0        EW   SS   EK             FP        0    True\n",
      "874        246          0        EW   SS   CK             FP        0    True\n",
      "875        246          0        NS   SS   CK             FP        0    True\n",
      "878        246       1289        EW   ID   EK             FP        0    True\n",
      "880        246       1330        EW   ID   EK             FP        0    True\n",
      "882        246       1392        EW   ID   CK             FP        0    True\n",
      "884        246       1581        EW   ID   CK             FP        0    True\n",
      "900        252       1285        EW   ID   EK             FP        0    True\n",
      "909        254       1537        EW   ID   EK             FP        0    True\n",
      "919        256       1537        EW   ID   EK             FP        0    True\n",
      "921        256       2062        EW   ID   NK             FP        0    True\n",
      "1090       283       1574        EW   IK   EK             FP        0    True\n",
      "1092       283       1581        EW   ID   EK             FP        0    True\n",
      "1802       414        425        EW   IK   CK             FP        0    True\n",
      "1804       414        432        EW   ID   EK             FP        0    True\n",
      "1961       440       1676        EW   IK   EK             FP        0    True\n",
      "1963       440       1682        EW   ID   EK             FP        0    True\n",
      "2253       486       1545        EW   IK   EK             FP        0    True\n",
      "2483       523       1283        EW   IK   EK             FP        0    True\n",
      "2485       523       1312        NS   AD   NK             FP        0    True\n",
      "2493       524       1283        EW   IK   EK             FP        0    True\n",
      "2495       524       1312        NS   AD   NK             FP        0    True\n",
      "2499       525         76        EW   AD   NK             FP        0    True\n",
      "2501       525        104        NS   IK   CK             FP        0    True\n",
      "2513       527        199        NS   IK   CK             FP        0    True\n",
      "2545       533        878        EW   IK   CK             FP        0    True\n",
      "2547       533        894        NS   IK   CK             FP        0    True\n",
      "2642       552        646        NS   AD   NK             FP        0    True\n",
      "2871       598       1003        EW   IK   CK             FP        0    True\n",
      "2873       598       1017        NS   AD   NK             FP        0    True\n",
      "6320      1180          0        EW   SS   EK             FP        0    True\n",
      "6363      1201          0        NS   SS   CK             FP        0    True\n",
      "6376      1207          0        EW   SS   EK             FP        0    True\n",
      "6429      1233          0        EW   SS   CK             FP        0    True\n",
      "7221      1366       1649        NS   ID   CK             FP        0    True\n",
      "8109      1510       1711        EW   IK   HK             FP        0    True\n"
     ]
    }
   ],
   "source": [
    "print(total_df.loc[(total_df['classification']=='FP') & (total_df['matched']==True)].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    time  node\n",
      "0      0  blue\n",
      "1      1  blue\n",
      "2      2  blue\n",
      "3      3  blue\n",
      "4      4  blue\n",
      "5      5  blue\n",
      "6      6  blue\n",
      "7      7  blue\n",
      "8      8  blue\n",
      "9      9  blue\n",
      "10     5   bla\n",
      "11     7   bla\n",
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5      True\n",
      "6     False\n",
      "7      True\n",
      "8     False\n",
      "9     False\n",
      "10     True\n",
      "11     True\n",
      "dtype: bool\n",
      "    time     node\n",
      "0      0     blue\n",
      "1      1     blue\n",
      "2      2     blue\n",
      "3      3     blue\n",
      "4      4     blue\n",
      "5      5  UNKNOWN\n",
      "6      6     blue\n",
      "7      7  UNKNOWN\n",
      "8      8     blue\n",
      "9      9     blue\n",
      "10     5  UNKNOWN\n",
      "11     7  UNKNOWN\n",
      "   time     node\n",
      "0     0     blue\n",
      "1     1     blue\n",
      "2     2     blue\n",
      "3     3     blue\n",
      "4     4     blue\n",
      "5     5  UNKNOWN\n",
      "6     6     blue\n",
      "7     7  UNKNOWN\n",
      "8     8     blue\n",
      "9     9     blue\n"
     ]
    }
   ],
   "source": [
    "test = range(10)\n",
    "tmp_df = pd.DataFrame({'time':range(10), 'node' : 'blue'})\n",
    "tmp_df2 = pd.DataFrame({'time':[5,7], 'node' : 'bla'})\n",
    "tmp_df = pd.concat([tmp_df, tmp_df2]).reset_index(drop=True)\n",
    "print(tmp_df.head(20))\n",
    "\n",
    "duplicate_indices = tmp_df.duplicated(subset=['time'], keep=False) # returns index of all duplicates\n",
    "print(duplicate_indices)\n",
    "tmp_df.loc[duplicate_indices==True, 'node'] = 'UNKNOWN'\n",
    "print(tmp_df.head(20))\n",
    "duplicate_indices_keep_first = tmp_df.duplicated(subset=['time'], keep='first') # returns index of all duplicates except the first\n",
    "\n",
    "tmp_df = tmp_df[duplicate_indices_keep_first==False]\n",
    "print(tmp_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.005>\n"
     ]
    }
   ],
   "source": [
    "print(dense_model.model.optimizer.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/splid-gpu/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(ds_gen.scaler, open('submission/models/ew_ns_classifier_scaler_oneshot_cnn.pkl', 'wb'))\n",
    "dense_model.model.save('submission/models/ew_ns_classifier_oneshot_cnn.hdf5')\n",
    "\n",
    "#0.12 0.92 0.950 (no dropout, strong overfitting, no ft-transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splid-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

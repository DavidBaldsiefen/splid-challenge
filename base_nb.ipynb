{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\David\\anaconda3\\envs\\splid\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from base import utils, datahandler, prediction_models, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths\n",
    "challenge_data_dir = Path('dataset/')\n",
    "data_dir = challenge_data_dir / \"train\"\n",
    "labels_dir = challenge_data_dir / 'train_labels.csv'\n",
    "\n",
    "split_dataframes = datahandler.load_and_prepare_dataframes(data_dir, labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Eccentricity  Semimajor Axis (m)  Inclination (deg)  RAAN (deg)  \\\n",
      "0      0.000347        4.216596e+07           0.086842  100.429836   \n",
      "1      0.000330        4.216501e+07           0.087069  100.364896   \n",
      "2      0.000310        4.216504e+07           0.087199  100.372568   \n",
      "3      0.000285        4.216590e+07           0.087205  100.371093   \n",
      "4      0.000269        4.216669e+07           0.087168  100.304063   \n",
      "5      0.000271        4.216673e+07           0.087198  100.177728   \n",
      "6      0.000282        4.216608e+07           0.087352  100.050185   \n",
      "7      0.000294        4.216512e+07           0.087591   99.987347   \n",
      "8      0.000308        4.216486e+07           0.087784  100.003110   \n",
      "9      0.000328        4.216535e+07           0.087827  100.018797   \n",
      "\n",
      "   Argument of Periapsis (deg)  Mean Anomaly (deg)  True Anomaly (deg)  \\\n",
      "0                    61.108170           81.312175           81.351468   \n",
      "1                    56.813370          115.754984          115.789048   \n",
      "2                    53.677774          148.967209          148.985498   \n",
      "3                    51.046035         -178.316583          181.682459   \n",
      "4                    48.309985         -145.432682          214.549807   \n",
      "5                    47.835903         -114.752443          245.219334   \n",
      "6                    50.823376          -87.531706          272.436014   \n",
      "7                    56.190394          -62.753179          297.216861   \n",
      "8                    59.971717          -36.466300          323.512717   \n",
      "9                    62.872320           -9.298870          350.695063   \n",
      "\n",
      "   Latitude (deg)  Longitude (deg)  Altitude (m)  ...     Vy (m/s)  Vz (m/s)  \\\n",
      "0       -0.005453       -96.962434  3.578562e+07  ... -1402.130899 -3.694344   \n",
      "1        0.016071       -96.966735  3.579292e+07  ...   158.225923 -4.632621   \n",
      "2        0.033164       -96.980346  3.579810e+07  ...  1675.318546 -4.317130   \n",
      "3        0.041298       -96.998728  3.579977e+07  ...  2741.138870 -2.833070   \n",
      "4        0.038349       -97.016588  3.579791e+07  ...  3069.174923 -0.580569   \n",
      "5        0.025159       -97.029610  3.579338e+07  ...  2571.011744  1.833292   \n",
      "6        0.005308       -97.035139  3.578743e+07  ...  1380.256143  3.757153   \n",
      "7       -0.015844       -97.032254  3.578131e+07  ...  -182.882143  4.670019   \n",
      "8       -0.032612       -97.021447  3.577628e+07  ... -1697.336496  4.321233   \n",
      "9       -0.040523       -97.004942  3.577359e+07  ... -2754.602962  2.799645   \n",
      "\n",
      "   ObjectID  TimeIndex       EW  EW_Node  EW_Type       NS  NS_Node  NS_Type  \n",
      "0         1          0  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  \n",
      "1         1          1  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  \n",
      "2         1          2  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  \n",
      "3         1          3  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  \n",
      "4         1          4  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  \n",
      "5         1          5  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  \n",
      "6         1          6  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  \n",
      "7         1          7  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  \n",
      "8         1          8  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  \n",
      "9         1          9  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  UNKNOWN  \n",
      "\n",
      "[10 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(split_dataframes['1'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SS-CK', 'SS-HK', 'SS-EK']\n",
      "['SS-CK', 'SS-HK']\n",
      "['SS-NK', 'IK-CK', 'SS-CK', 'SS-HK', 'IK-HK']\n",
      "['SS-NK', 'IK-CK', 'SS-HK']\n"
     ]
    }
   ],
   "source": [
    "# get all labels in the dataframes\n",
    "keys_list = list(split_dataframes.keys())\n",
    "random.Random(69).shuffle(keys_list) # shuffle, but with a seed for reproducability\n",
    "split_idx = int(len(keys_list) * 0.8)\n",
    "train_keys = keys_list[:split_idx]\n",
    "train_labels_EW = []\n",
    "train_labels_NS = []\n",
    "val_keys = keys_list[split_idx:]\n",
    "val_labels_EW = []\n",
    "val_labels_NS = []\n",
    "for key in train_keys:\n",
    "    train_labels_EW += list(split_dataframes[key]['EW'].unique())\n",
    "    train_labels_NS += list(split_dataframes[key]['NS'].unique())\n",
    "for key in val_keys:\n",
    "    val_labels_EW += list(split_dataframes[key]['EW'].unique())\n",
    "    val_labels_NS += list(split_dataframes[key]['NS'].unique())\n",
    "train_labels_EW = list(dict.fromkeys(train_labels_EW))\n",
    "train_labels_NS = list(dict.fromkeys(train_labels_NS))\n",
    "val_labels_EW = list(dict.fromkeys(val_labels_EW))\n",
    "val_labels_NS = list(dict.fromkeys(val_labels_NS))\n",
    "print(train_labels_EW)\n",
    "print(val_labels_EW)\n",
    "print(train_labels_NS)\n",
    "print(val_labels_NS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset from 15 train and 3 val objects\n",
      "Created datasets with seed 69\n",
      "(TensorSpec(shape=(None, 5, 16), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "ds_gen = datahandler.DatasetGenerator(split_df=split_dataframes, train_val_split=0.85, stride=1, input_steps=5, seed=69)\n",
    "train_EW, train_NS, val_EW, val_NS = ds_gen.get_datasets(64, shuffle=True)\n",
    "\n",
    "print(train_EW.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\David\\anaconda3\\envs\\splid\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Training model #1\n",
      "WARNING:tensorflow:From c:\\Users\\David\\anaconda3\\envs\\splid\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\David\\anaconda3\\envs\\splid\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Training model #2\n",
      "EW results:\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 1.8097e-04 - accuracy: 1.0000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 3.4380 - accuracy: 0.5632\n",
      "NS results:\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9958\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 16.3553 - accuracy: 0.2899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16.35527801513672, 0.2899017930030823]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_EW, train_NS, val_EW, val_NS = ds_gen.get_datasets(128, shuffle=True)\n",
    "#dense_model_ew = prediction_models.Dense_NN(train_EW, dense_layers=[512,256,32], l2_reg=0.0001, mixed_dropout=0.2)\n",
    "#dense_model_ns = prediction_models.Dense_NN(train_EW, dense_layers=[512,256,32], l2_reg=0.0001, mixed_dropout=0.2)\n",
    "dense_model_ew = prediction_models.CNN(train_EW, conv_layers=[64,64,64], l2_reg=0.00, mixed_dropout=0.0)\n",
    "dense_model_ns = prediction_models.CNN(train_EW, conv_layers=[64,64,64], l2_reg=0.00, mixed_dropout=0.0)\n",
    "print(\"Training model #1\")\n",
    "hist_ew = dense_model_ew.fit(train_EW, val_ds=val_EW, epochs=40, verbose=0, plot_hist=False) # TODO: somehow this sometimes has save_best_only enabled?? even though its only enabled in 2nd fit? ... do inherited models somehow modify the mother class?!?\n",
    "print(\"Training model #2\")\n",
    "hist_ns = dense_model_ns.fit(train_NS, val_ds=val_NS, epochs=40, verbose=0, plot_hist=False)\n",
    "print(\"EW results:\")\n",
    "dense_model_ew.model.evaluate(train_EW)\n",
    "dense_model_ew.model.evaluate(val_EW)\n",
    "print(\"NS results:\")\n",
    "dense_model_ns.model.evaluate(train_NS)\n",
    "dense_model_ns.model.evaluate(val_NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find out if we can directly train for precision/challenge metrics\n",
    "# TODO: maybe it makes sense to look at values before and after the node? Given that we are trying to detect changes...\n",
    "# TODO: check if train_NS even contains all the labels in val_NS... in general, train should contain all labels\n",
    "# TODO: Make sure labelencoder gets saved\n",
    "# TODO: Enable dataset generation with different label features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_submission_evaluation(ds_EW, ds_NS, label_encoder, model_ew, model_ns):\n",
    "    # This approach is dirty, but serves the purpose well\n",
    "    # inputs and identifiers are identical for both sets\n",
    "    inputs = np.concatenate([element for element in ds_EW.map(lambda x,y,z: x).as_numpy_iterator()])\n",
    "    labels_EW = np.concatenate([element for element in ds_EW.map(lambda x,y,z: y).as_numpy_iterator()]).reshape(-1,1) # turn (n,) to (n,1)\n",
    "    labels_NS = np.concatenate([element for element in ds_NS.map(lambda x,y,z: y).as_numpy_iterator()]).reshape(-1,1)\n",
    "    identifiers = np.concatenate([element for element in ds_EW.map(lambda x,y,z: z).as_numpy_iterator()])#[:,0,:]\n",
    "    #print(inputs.shape, labels_EW.shape, labels_NS.shape, identifiers.shape)\n",
    "    # perform evaluation and prediction\n",
    "    model_ew.evaluate(inputs, labels_EW)\n",
    "    model_ns.evaluate(inputs, labels_NS)\n",
    "    preds_ew = model_ew.predict(inputs)\n",
    "    preds_ew_argmax = np.argmax(preds_ew, axis=1).reshape(-1,1)\n",
    "    preds_ns = model_ns.predict(inputs)\n",
    "    preds_ns_argmax = np.argmax(preds_ns, axis=1).reshape(-1,1)\n",
    "    # create dataframe that contains all the necessary data\n",
    "    df = pd.DataFrame(np.concatenate([identifiers.reshape(-1,2), labels_EW, preds_ew_argmax, labels_NS, preds_ns_argmax], axis=1), columns=['ObjectID', 'TimeIndex', 'EW', 'Predicted_EW', 'NS', 'Predicted_NS'], dtype=np.int32)\n",
    "    # now remove unnecessary columns, decode prediction\n",
    "    df['Predicted_EW'] = label_encoder.inverse_transform(df['Predicted_EW'])\n",
    "    df['Predicted_NS'] = label_encoder.inverse_transform(df['Predicted_NS'])\n",
    "    df['EW'] = label_encoder.inverse_transform(df['EW'])\n",
    "    df['NS'] = label_encoder.inverse_transform(df['NS'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_EW, train_NS, val_EW, val_NS = ds_gen.get_datasets(32, shuffle=False, with_identifiers=True)\n",
    "ground_truth = pd.read_csv(challenge_data_dir / 'train_labels.csv')\n",
    "ground_truth_train = ground_truth[ground_truth['ObjectID'].isin(map(int, ds_gen.train_keys))].copy()\n",
    "ground_truth_val = ground_truth[ground_truth['ObjectID'].isin(map(int, ds_gen.val_keys))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019/1019 [==============================] - 2s 2ms/step - loss: 4.9302e-06 - accuracy: 1.0000\n",
      "1019/1019 [==============================] - 2s 2ms/step - loss: 0.0089 - accuracy: 0.9963\n",
      "1019/1019 [==============================] - 2s 2ms/step\n",
      "1019/1019 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Smoothing: 100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for the train set: 0.66\n",
      "Recall for the train set: 0.63\n",
      "F2 for the train set: 0.64\n",
      "RMSE for the train set: 0.37\n"
     ]
    }
   ],
   "source": [
    "df_train=perform_submission_evaluation(train_EW, train_NS, ds_gen.label_encoder, dense_model_ew.model, dense_model_ns.model)\n",
    "smoothed_df_train = utils.smooth_predictions(df_train, past_steps=3, fut_steps=4)\n",
    "train_results = utils.convert_classifier_output(smoothed_df_train).sort_values(['ObjectID']).reset_index(drop=True)\n",
    "evaluator = evaluation.NodeDetectionEvaluator(ground_truth_train, train_results)\n",
    "precision, recall, f2, rmse = evaluator.score()\n",
    "print(f'Precision for the train set: {precision:.2f}')\n",
    "print(f'Recall for the train set: {recall:.2f}')\n",
    "print(f'F2 for the train set: {f2:.2f}')\n",
    "print(f'RMSE for the train set: {rmse:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 2ms/step - loss: 13.8889 - accuracy: 0.5606\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 38.0639 - accuracy: 0.3017\n",
      "204/204 [==============================] - 0s 2ms/step\n",
      "204/204 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Smoothing: 100%|██████████| 3/3 [00:03<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for the val set: 0.02\n",
      "Recall for the val set: 0.20\n",
      "F2 for the val set: 0.07\n",
      "RMSE for the val set: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_val=perform_submission_evaluation(val_EW, val_NS, ds_gen.label_encoder, dense_model_ew.model, dense_model_ns.model)\n",
    "smoothed_df_val = utils.smooth_predictions(df_val)\n",
    "val_results = utils.convert_classifier_output(smoothed_df_val).sort_values(['ObjectID']).reset_index(drop=True)\n",
    "evaluator = evaluation.NodeDetectionEvaluator(ground_truth_val, val_results)\n",
    "precision, recall, f2, rmse = evaluator.score()\n",
    "print(f'Precision for the val set: {precision:.2f}')\n",
    "print(f'Recall for the val set: {recall:.2f}')\n",
    "print(f'F2 for the val set: {f2:.2f}')\n",
    "print(f'RMSE for the val set: {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset from 18 train and 0 val objects\n",
      "Created datasets with seed 42\n",
      "Training model #1\n",
      "Training model #2\n",
      "Evaluation:\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 0.0524 - accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "ds_gen_noval = datahandler.DatasetGenerator(split_df=split_dataframes, train_val_split=1.0, stride=1, input_steps=15)\n",
    "train_EW, train_NS = ds_gen_noval.get_datasets(128, shuffle=True)\n",
    "dense_model_ew = prediction_models.Dense_NN(train_EW, dense_layers=[128,128], l2_reg=0.0002, mixed_dropout=0.1)\n",
    "dense_model_ns = prediction_models.Dense_NN(train_EW, dense_layers=[128,128], l2_reg=0.0002, mixed_dropout=0.1)\n",
    "print(\"Training model #1\")\n",
    "hist_ew = dense_model_ew.fit(train_EW, epochs=40, verbose=0, plot_hist=False) # TODO: somehow this sometimes has save_best_only enabled?? even though its only enabled in 2nd fit? ... do inherited models somehow modify the mother class?!?\n",
    "print(\"Training model #2\")\n",
    "hist_ns = dense_model_ns.fit(train_NS, epochs=40, verbose=0, plot_hist=False)\n",
    "print(\"Evaluation:\")\n",
    "eval_res = dense_model_ew.model.evaluate(train_EW)\n",
    "eval_res = dense_model_ns.model.evaluate(train_NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\anaconda3\\envs\\splid\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "dense_model_ew.model.save('trained_models/dense_model_ew.h5')\n",
    "dense_model_ns.model.save('trained_models/dense_model_ns.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 1s 2ms/step\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 15, 16)]          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 240)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               30848     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49940 (195.08 KB)\n",
      "Trainable params: 49940 (195.08 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('trained_models/dense_model_ew.h5')\n",
    "new_model.predict(train_EW)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for the val set: 0.73\n",
      "Recall for the val set: 0.65\n",
      "F2 for the val set: 0.66\n",
      "RMSE for the val set: 0.46\n"
     ]
    }
   ],
   "source": [
    "ground_truth = pd.read_csv(challenge_data_dir / 'train_labels.csv')\n",
    "predictions_final = pd.read_csv('submission/submission.csv')\n",
    "evaluator = evaluation.NodeDetectionEvaluator(ground_truth, predictions_final)\n",
    "precision, recall, f2, rmse = evaluator.score()\n",
    "print(f'Precision for the val set: {precision:.2f}')\n",
    "print(f'Recall for the val set: {recall:.2f}')\n",
    "print(f'F2 for the val set: {f2:.2f}')\n",
    "print(f'RMSE for the val set: {rmse:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
